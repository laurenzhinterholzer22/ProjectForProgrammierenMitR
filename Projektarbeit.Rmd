---
title: "Projektarbeit"
author: "Laurenz Hinterholzer & Manuel Karlsberger"
date: "7/22/2020"
output:
  html_document:
    df_print: paged
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# **Aufgabe 1**
***

## Einlesen der Daten

```{r}
yearLsoa <- read.csv(file = "year_lsoa_grocery.csv", header = TRUE, sep =",")
lsoaArea <- yearLsoa$area_sq_km
lsoaPopulation <- yearLsoa$population

yearMsoa <- read.csv(file = "year_msoa_grocery.csv", header = TRUE, sep =",")
msoaArea <- yearMsoa$area_sq_km
msoaPopulation <- yearMsoa$population

yearOsward <- read.csv(file = "year_osward_grocery.csv", header = TRUE, sep =",")
oswardArea <- yearOsward$area_sq_km
oswardPopulation <- yearOsward$population

yearBorough <- read.csv(file = "year_borough_grocery.csv", header = TRUE, sep = ",")
boroughArea <- yearBorough$area_sq_km
boroughPopulation <- yearBorough$population

```
## Bestimmung der Gesamtbevoelkerung, Gesamtflaeche und relativen porzentuellen Abweichungen
 
 
```{r results="hide"}
areas <- list(lsoa = lsoaArea, msoa =  msoaArea,  ward = oswardArea, borough = boroughArea)
population <- list(lsoa = lsoaPopulation, msoa = msoaPopulation, ward = oswardPopulation, borough = boroughPopulation)

lapply(areas, sum)     
lapply(population, sum)    


relDif <- function(var){
  x <- numeric()
  for (i in seq_along(var)){
    x <- append(x, round((max(var)-var[i])/max(var)*100,2))
  }
  return(x)
}

lapply(areas, relDif)
lapply(population, relDif)
```
Nachdem die vier Aggregationsgrade eingelesen und nach der Flaeche und Bevoelkerung jeweils getrennt und gelistet wurden, haben wir mit lapply jeweils die Gesamtflaeche und Gesamtbevoelkerung bestimmt.
Dabei wurde festgestellt, dass bis auf den Aggregationsgrad LSOA, alle Grade 1572.48km2 Flaeche und  8666930 Einwohner haben.
LSOA hat um 0,7 km2 weniger Flaeche und um 2822 weniger Einwohner als die Anderen.

Bei der Berechnung der jeweiligen relativen prozentuellen Abweichungen vom jeweiligen Maximum kann man aufgrund einiger Ausreißern bei allen Aggregationsgraden eine großteils hohe Abweichung vom Maximum feststellen.



## Dataframe 

```{r}
noAreas <- lapply(areas, length) 

tab1Dataframe <- data.frame(
  Area = c("LSOA","MSOA","Ward","Borough"),
  NumberOfAreas = unlist(noAreas),
  AvgSurfaces = round(unlist(Map("/", lapply(areas, sum), noAreas)),2),
  AvgPopulation = round(unlist(Map("/", lapply(population, sum), noAreas)),0),
  MedianPopulation = unlist(lapply(population, median)),
  MedianArea = unlist(lapply(areas, median)),
  stringsAsFactors = FALSE
)
rownames(tab1Dataframe) <- NULL
tab1Dataframe
```
Der Dataframe der Tabelle 1 in Aiello et al. (2020) ist annaehernd der selbe wie den wir reproduziert haben. Ein kleiner Unterschied kann man bei der durchschnittlichen Flaeche bei dem Aggregationsgrad Borough festellen, wobei dieser Unterschied auch ein Rundungsfehler sein koennte.

## Visualisierung

```{r}
par(mfrow=c(1,2))
hist(lsoaPopulation, main = "Lsoa Bevoelkerung", xlab = "Bevoelkerung", ylab = "Haeufigkeit",breaks= seq(min(lsoaPopulation),max(lsoaPopulation)+100, 200), col =3, freq = FALSE, xlim = c(0,4000))
hist(lsoaArea, main = "Lsoa Flaeche",xlab = "Flaeche", ylab = "Haeufigkeit", breaks= seq(min(lsoaArea),max(lsoaArea)+0.5, 0.5), col =4, freq = FALSE, xlim = c(0,4))

```
    
  Schlussendlich wurden die Daten des kleinsten Aggregationsgrades, also Lsoa, visualisiert. Um die Bevoelkerung und Flaeche zu visulisieren, haben wir ein Histogramm verwendet und die Daten bei der Bevoelkerung auf 0-4000 und bei der Flaeche auf 0-4 beschraenkt, um die Ausreisser zu eliminieren und 
die aussagekraeftigen Daten besser zu veranschaulichen. Die bevoelkerung hat die meisten Auspraegungen bei ca 1800 und die Flaeche zwischen 0 und 1.

# **Aufgabe 2**
***
## Einlesen der Daten

```{r results="hide"}
library(sf)
boundariesLondon <- st_read("./statistical-gis-boundaries-london/statistical-gis-boundaries-london/ESRI/LSOA_2011_London_gen_MHW.shp")
```

## Bestimmung von Klasse, Dimensionen und Spaltennamen

```{r}
class(boundariesLondon)
dim(boundariesLondon)
colnames(boundariesLondon)
```

## Verknuepfung der Daten mit Lsoa

```{r}
mergeboundaries <- merge(boundariesLondon, yearLsoa, by.x = "LSOA11CD", by.y = "area_id")
class(mergeboundaries)
dim(mergeboundaries)    
colnames(mergeboundaries)
```
## Visualisierung

```{r}
library("colorspace")

par(mfrow=c(1,2))

plot(mergeboundaries["num_transactions"], logz = TRUE, main = "Number of Transactions", pal = terrain_hcl)

mergeboundaries$perresident <- mergeboundaries$num_transactions/mergeboundaries$population
plot(mergeboundaries["perresident"], logz = TRUE, main = "Transactions per resident", pal = terrain_hcl) 
```
    
  Bei der Reproduktion der Grafik Abbildung 3 in Aiello et al. (2020) erkennt man bis auf die Farbpalette keine Unterschiede. Weiters ist die Grafik welche die Anzahl der Transaktionen visualisiert, bis auf die Skalierung annaehernd ident.

# **Aufgabe 3**
***
## Visualisierung

```{r}
sequ <- seq(0, 1, by = 0.01)

dat <- list(lsoa = yearLsoa, msoa = yearMsoa, ward = yearOsward)

repr <- function(var){
  x <- numeric()
  for(i in sequ){
    x <- append(x, nrow(var[var$representativeness_norm > i,])/nrow(var))
  }
  return(list(seq = sequ, perc = x))
}

normRepr <- lapply(dat, repr)

par(mfrow=c(1,1))
plot(as.data.frame(normRepr$lsoa), main = "Representativitaet", xlab = "Threshold")
lines(as.data.frame(normRepr$msoa), lty = 1)
lines(as.data.frame(normRepr$ward), lty = 2)
legend("topright", c("lsoa", "msoa", "ward"), lty = c(NA,1,2), pch = c(1,NA,NA))
```
  
  Bei dieser Grafik wird mithilfe der Daten von Lsoa,Msoa und Ward die Abbildung 4 links in Aiello et al. (2020) visualisiert. Wobei man bei dieser Grafik schon einen deutlichen Unterschied zu der Grafik in Aiello sieht. Bei Aiello sind die drei Aggregationsgrade annaehernd ident und naehern sich bereits bei 0.4 Threhold der X-Achse. Bei unserer Grafik verhaelt  sich nur Lsoa wie bei Aello und Msoa und Ward flachen erst ab 0.5 ab und schneiden erst bei 0.8 der X-Achse.

# **Aufgabe 4**
***
## Visualisierung

```{r}
energyTot <- yearMsoa$energy_tot
energyFatTot <- yearMsoa$energy_fat / energyTot
energyFibreTot <- yearMsoa$energy_fibre / energyTot
energySatTot <- yearMsoa$energy_saturate / energyTot
energyCarbTot <- yearMsoa$energy_carb / energyTot
energySugarTot <- yearMsoa$energy_sugar / energyTot
energyProteinTot <- yearMsoa$energy_protein / energyTot

par(mfrow=c(2,3))

h <- hist(energyCarbTot, breaks=seq(0,0.6,length=75), plot = F)
h$density <- h$counts/sum(h$counts)
plot(h, main = NULL, xlab = "Energie von Kohlenhydraten",xlim = c(0,0.6), ylim = c(0,0.6), col = "red", freq = F)

h <- hist(energyFatTot, breaks=seq(0,0.6,length=75), plot = F)
h$density <- h$counts/sum(h$counts)
plot(h, main = NULL, xlab = "Energie von Fetten",xlim = c(0,0.6), ylim = c(0,0.6), col = "purple", freq = F)

h <- hist(energySatTot, breaks=seq(0,0.6,length=75), plot = F)
h$density <- h$counts/sum(h$counts)
plot(h, main = NULL, xlab = "Energie von Saturated",xlim = c(0,0.6), ylim = c(0,0.6), col = "pink", freq = F)

h <- hist(energySugarTot, breaks=seq(0,0.6,length=75), plot = F)
h$density <- h$counts/sum(h$counts)
plot(h, main = NULL, xlab = "Energie von Zucker",xlim = c(0,0.6), ylim = c(0,0.6), col = "orange", freq = F)

h <- hist(energyProteinTot, breaks=seq(0,0.6,length=75), plot = F)
h$density <- h$counts/sum(h$counts)
plot(h, main = NULL, xlab = "Energie von Eiweiß",xlim = c(0,0.6), ylim = c(0,0.6), col = "green", freq = F)

h <- hist(energyFibreTot, breaks=seq(0,0.6,length=75), plot = F)
h$density <- h$counts/sum(h$counts)
plot(h, main = NULL, xlab = "Energie von Ballaststoffe",xlim = c(0,0.6), ylim = c(0,0.6), col = "lightgreen", freq = F)
```

Bei diesen 6 Histogrammen haben wir die Energie der 6 Naehrstoffe dargestellt.Auf der Y-Achse ist die Dichte und auf der X-Achse die Energie Abgebildet. Der Naehrstoff mit der meisten Energie ist das Fett welches zwischen 0.4 und 0.5 bewegt. Danach kommen Kohlenhydrate, Zucker, Satured, Eiwess und am wenigsten Energie haben die Ballaststoffe.


# **Aufgabe 5**
***
## Einlesen der Daten

```{r results="hide"}
diabetes <- read.table("diabetes_estimates_osward_2016.csv", header = TRUE, sep = ",")
head(diabetes)

londonWardX <- st_read("./statistical-gis-boundaries-london/statistical-gis-boundaries-london/ESRI/London_Ward_CityMerged.shp")
londonWardY <- st_read("./London-wards-2014/London-wards-2014 (1)/London-wards-2014_ESRI/London_Ward_CityMerged.shp")
```

## Funktion

```{r results="hide"}
compare_data <- function(x, y, id.x, id.y = id.x, var.x = character(0), var.y = var.x, FUN = sum, ...) {
  # Argumentüberprüfung muss noch bearbeitet werden!!!
  
  # Zwei Listen müssen übergeben werden, ansonsten nicht genügend Daten
  if(!is.list(x) | !is.list(y))
    stop("Bitte überprüfen Sie Ihre Eingabe für x und y!")
  # ID muss als String übergeben werden (zumindest x, y nicht unbedingt. Wenn y übergeben wird, muss es auch ein String sein)
  if(!is.character(id.x) | ((id.x != id.y) & !is.character(id.y)))
    stop("es muss eine korrekte ID angegeben werden!")
  # Variable muss als String übergeben werden (zumindest x, y nicht unbedingt. Wenn y übergeben wird, muss es auch ein String sein)
  if(!is.character(var.x) | ((var.x != var.y) & !is.character(var.y)))
    stop("es muss eine korrekte Variable angegeben werden!")
  
  
  #spezielle Behandlung bei merge von 2 sf Objekten (vllt st_join) muss man sich noch anschauen
  if(class(x)[1] == "sf" & class(y)[1] == "sf"){
    mergedXandY <- merge(x %>% as.data.frame(), y %>% as.data.frame(), by.x = id.x, by.y = id.y)
    mergedXandY %>% st_sf(sf_column_name = 'geometry.x')
    mergedX <- merge(x %>% as.data.frame(), y %>% as.data.frame(), by.x = id.x, by.y = id.y, all.x = TRUE)
    mergedX %>% st_sf(sf_column_name = 'geometry.x')
    mergedY <- merge(x %>% as.data.frame(), y %>% as.data.frame(), by.x = id.x, by.y = id.y, all.y = TRUE)
    mergedY %>% st_sf(sf_column_name = 'geometry.y')
    
    sumXandY <- (FUN(get(paste(var.x, ".x",sep = ""), mergedXandY), ...))
    sumX <- (FUN(get(paste(var.x,".x",sep = ""), mergedX), ...))
    sumY <- (FUN(get(paste(var.x,".y",sep = ""), mergedY),...))
  }
  else{
    mergedXandY <- merge(x, y, by.x = id.x, by.y = id.y)
    mergedX <- merge(x, y, by.x = id.x, by.y = id.y, all.x = TRUE)
    mergedY <- merge(x, y, by.x = id.x, by.y = id.y, all.y = TRUE)
    
    sumXandY <- (FUN(get(var.x, mergedXandY), ...))
    sumX <- (FUN(get(var.x, mergedX), ...))
    sumY <- (FUN(get(var.x, mergedY),...))
  }
  
  
  df <- data.frame(mergeType = c("X und Y", "nur X", "nur Y"), 
                   anzahl = c(nrow(mergedXandY),nrow(mergedX)-nrow(mergedXandY), nrow(mergedY)-nrow(mergedXandY)),
                   hektar = c(round(sumXandY,0), round(sumX-sumXandY,0), round(sumY-sumXandY,0)))
  
  # wenn separate Variablen betrachtet werden sollen
  if(var.x != var.y){
    popXandY <- (FUN(get(var.y, mergedXandY), ...))
    popX <- (FUN(get(var.y, mergedX), ...))
    popY <- (FUN(get(var.y, mergedY), ...))
    df$hektar <- df$hektar*100
    df <- cbind(df, bevölkerung = c(popXandY, popX-popXandY, popY-popXandY))
  }
 
  return(df)
}
```

## Anwendung der Funktion

```{r}
compare_data(londonWardX, londonWardY, "GSS_CODE", "GSS_CODE", "HECTARES", "HECTARES", na.rm = TRUE)
compare_data(diabetes, londonWardY, "area_id", "GSS_CODE", "HECTARES", na.rm= TRUE)
compare_data(diabetes, yearOsward, "area_id", "area_id", "area_sq_km", "population", na.rm = TRUE)
```


# **Aufgabe 6**
***
## Verknuepfung der Daten

```{r results="hide"}
merged <- merge(yearOsward, diabetes, by= "area_id")
```

## Berechnung des Zusammenhangs

```{r}
corr <- cor.test(merged$estimated_diabetes_prevalence, merged$energy_tot, method = "spearman")
corr
```

## Visualisierung

```{r}
par(mfrow=c(1,1))
plot(merged$estimated_diabetes_prevalence, merged$energy_tot, main = "Streudiagramm", xlab = "geschätzte Diabetes-Prävalenz", ylab = "Energie der Nährstoffe")
```

Bei dieser Aufgabe wurden die Daten aus year_osward_grocery.csv mit der Information in
diabetes_estimates_osward_2016.csv. verknuepft und die Korrelation zwischen der geschaetzten 
Diabetes Praevalenz und der Energie der Naehrstoffe berechnet und mit einem Streudiagramm visualisiert. Die Korrelation mithilfe von Spearman ist 0.58 alos gibt es einen starken positiven Zusammenhang der beiden Vriablen. Dieses ergebnis gbestaetigt das streudiagramm welches eine positive Steigung hat. 
