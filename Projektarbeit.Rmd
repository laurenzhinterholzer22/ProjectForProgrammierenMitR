---
title: "Projektarbeit"
author: "Laurenz Hinterholzer & Manuel Karlsberger"
date: "7/22/2020"
output:
  html_document:
    df_print: paged
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# **Aufgabe 1**
***
Tabelle 1 in Aiello et al. (2020) gibt einen Überblick über die Regionen je nach Aggregationsgrad nach Anzahl,
durchschnittlicher Fläche und durchschnittlicher Anzahl an Bevölkerung.
Die Daten dazu sind enthalten in den Dateien year_*_grocery.csv, wobei * entweder borough, lsoa, msoa
oder osward ist. Die Variablen area_sq_km und population enthalten die Information bzgl. Fläche und
Bevölkerung.
  
* Laden Sie die Daten in R ein   
* Überprüfen Sie, ob die Gesamtbevölkerung und Gesamtfläche gleich ist, egal welcher Aggregationsgrad
verwendet wird. Bestimmen Sie die relativen prozentuellen Abweichungen vom jeweiligen Maximum. 
* Erstellen Sie einen Dataframe in R, der Tabelle 1 in Aiello et al. (2020) reproduziert. Prüfen Sie, ob die exakt selben Ergebnisse reproduzierbar sind.
* Ergänzen Sie den Dataframe, indem Sie auch den Median der Bevölkerung und Fläche bestimmen.
* Visualisierung Sie die Verteilung von Bevölkerung und Fläche fur den kleinsten Aggregationsgrad.
* Interpretieren Sie die Ergebnisse.
  
  



## Einlesen der Daten

```{r}
yearLsoa <- read.csv(file = "year_lsoa_grocery.csv", header = TRUE, sep =",")
lsoaArea <- yearLsoa$area_sq_km
lsoaPopulation <- yearLsoa$population

yearMsoa <- read.csv(file = "year_msoa_grocery.csv", header = TRUE, sep =",")
msoaArea <- yearMsoa$area_sq_km
msoaPopulation <- yearMsoa$population

yearOsward <- read.csv(file = "year_osward_grocery.csv", header = TRUE, sep =",")
oswardArea <- yearOsward$area_sq_km
oswardPopulation <- yearOsward$population

yearBorough <- read.csv(file = "year_borough_grocery.csv", header = TRUE, sep = ",")
boroughArea <- yearBorough$area_sq_km
boroughPopulation <- yearBorough$population

```
## Bestimmung der Gesamtbevölkerung, Gesamtfläche und relativen prozentuellen Abweichungen
 
 
```{r results="hide"}
areas <- list(lsoa = lsoaArea, msoa =  msoaArea,  ward = oswardArea, borough = boroughArea)
population <- list(lsoa = lsoaPopulation, msoa = msoaPopulation, ward = oswardPopulation, borough = boroughPopulation)

lapply(areas, sum)     
lapply(population, sum)    


relDif <- function(var){
  x <- numeric()
  for (i in seq_along(var)){
    x <- append(x, round((max(var)-var[i])/max(var)*100,2))
  }
  return(x)
}

lapply(areas, relDif)
lapply(population, relDif)
```
Nachdem die vier Aggregationsgrade eingelesen und nach der Fläche und Bevölkerung jeweils getrennt und gelistet wurden, haben wir mit lapply jeweils die Gesamtfläche und Gesamtbevölkerung bestimmt.
Dabei wurde festgestellt, dass bis auf den Aggregationsgrad LSOA, alle Grade 1572.48km2 Fläche und  8666930 Einwohner haben.
LSOA hat um 0,7 km2 weniger Fläche und um 2822 weniger Einwohner als die Anderen.

Bei der Berechnung der jeweiligen relativen prozentuellen Abweichungen vom jeweiligen Maximum kann man aufgrund einiger Ausreißern bei allen Aggregationsgraden eine großteils hohe Abweichung vom Maximum feststellen.



## Dataframe 

```{r}
noAreas <- lapply(areas, length) 

tab1Dataframe <- data.frame(
  Area = c("LSOA","MSOA","Ward","Borough"),
  NumberOfAreas = unlist(noAreas),
  AvgSurfaces = round(unlist(Map("/", lapply(areas, sum), noAreas)),2),
  AvgPopulation = round(unlist(Map("/", lapply(population, sum), noAreas)),0),
  MedianPopulation = unlist(lapply(population, median)),
  MedianArea = unlist(lapply(areas, median)),
  stringsAsFactors = FALSE
)
rownames(tab1Dataframe) <- NULL
tab1Dataframe
```
Der Dataframe der Tabelle 1 in Aiello et al. (2020) ist annähernd der selbe wie den wir reproduziert haben. Ein kleiner Unterschied kann man bei der durchschnittlichen Fläche bei dem Aggregationsgrad Borough festellen, wobei dieser Unterschied auch ein Rundungsfehler sein könnte.

## Visualisierung

```{r}
par(mfrow=c(1,2))
hist(lsoaPopulation, main = "Lsoa Bevoelkerung", xlab = "Bevoelkerung", ylab = "Haeufigkeit",breaks= seq(min(lsoaPopulation),max(lsoaPopulation)+100, 200), col =3, freq = FALSE, xlim = c(0,4000))
hist(lsoaArea, main = "Lsoa Flaeche",xlab = "Flaeche", ylab = "Haeufigkeit", breaks= seq(min(lsoaArea),max(lsoaArea)+0.5, 0.5), col =4, freq = FALSE, xlim = c(0,4))

```
    
  Schlussendlich wurden die Daten des kleinsten Aggregationsgrades, also Lsoa, visualisiert. Um die Bevölkerung und Fläche zu visulisieren, haben wir ein Histogramm verwendet und die Daten bei der Bevölkerung auf 0-4000 und bei der Fläche auf 0-4 beschränkt, um die Ausreißer zu eliminieren und 
die aussagekräftigen Daten besser zu veranschaulichen. Die Bevölkerung hat die meisten Ausprägungen bei ca 1800 und die Fläche zwischen 0 und 1.

# **Aufgabe 2**
***
Abbildung 3 in Aiello et al. (2020) visualisiert die Anzahl der Transaktionen auf LSOA Level.  
  
* Entpacken Sie die Daten aus statistical-gis-boundaries-london.zip, sodass diese im Verzeichnis
statistical-gis-boundaries-london sind.
* Laden Sie die Daten statistical-gis-boundaries-london/ESRI/LSOA_2011_London_gen_MHW.shp mithilfe von st_read aus dem Paket sf in R ein.
* Bestimmen Sie die Klasse des Objekts sowie die Dimensionen und die Spaltennamen.
* Verknüpfen Sie das Objekt mit den Daten aus year_lsoa_grocery.csv anhand der Variable LSOA11CD
bzw. area_id. Bestimmen Sie die Klasse des Objekts sowie die Dimensionen und die Spaltennamen.
* Erstellen Sie die Grafik mit der Anzahl der Transaktionen. Achten Sie darauf, dass die Einteilung der
Farbskala auf der logarithmierten Skala erfolgt und übergeben Sie eine passende Palette via pal.
* Erstellen Sie eine analoge Grafik mit der Anzahl der Transaktionen pro Einwohner.
* Vergleichen Sie und interpretieren Sie die Grafiken.
  
## Einlesen der Daten

```{r results="hide"}
library(sf)
boundariesLondon <- st_read("./statistical-gis-boundaries-london/statistical-gis-boundaries-london/ESRI/LSOA_2011_London_gen_MHW.shp")
```

## Bestimmung von Klasse, Dimensionen und Spaltennamen

```{r}
class(boundariesLondon)
dim(boundariesLondon)
colnames(boundariesLondon)
```

## Verknüpfung der Daten mit Lsoa

```{r}
mergeboundaries <- merge(boundariesLondon, yearLsoa, by.x = "LSOA11CD", by.y = "area_id")
class(mergeboundaries)
dim(mergeboundaries)    
colnames(mergeboundaries)
```
## Visualisierung

```{r}
library("colorspace")

par(mfrow=c(1,2))

plot(mergeboundaries["num_transactions"], logz = TRUE, main = "Number of Transactions", pal = terrain_hcl)

mergeboundaries$perresident <- mergeboundaries$num_transactions/mergeboundaries$population
plot(mergeboundaries["perresident"], logz = TRUE, main = "Transactions per resident", pal = terrain_hcl) 
```
    
  Bei der Reproduktion der Grafik Abbildung 3 in Aiello et al. (2020) erkennt man bis auf die Farbpalette keine Unterschiede. Weiters ist die Grafik welche die Anzahl der Transaktionen visualisiert, bis auf die Skalierung annähernd ident.

# **Aufgabe 3**
***
Abbildung 4 links in Aiello et al. (2020) visualisiert den Prozentsatz an Fl¨ache mit der normierten Repräsentativiät über einem Schwellwert gegen den Schwellwert.  
  
* Verwenden Sie die Daten fur LSOA, MSOA und Ward, um die Grafik zu erzeugen.
* Vergleichen Sie Ihr Ergebnis mit der Grafik im Artikel und interpretieren Sie die Grafik.

## Visualisierung

```{r}
sequ <- seq(0, 1, by = 0.01)

dat <- list(lsoa = yearLsoa, msoa = yearMsoa, ward = yearOsward)

repr <- function(var){
  x <- numeric()
  for(i in sequ){
    x <- append(x, nrow(var[var$representativeness_norm > i,])/nrow(var))
  }
  return(list(seq = sequ, perc = x))
}

normRepr <- lapply(dat, repr)

par(mfrow=c(1,1))
plot(as.data.frame(normRepr$lsoa), main = "Representativitaet", xlab = "Threshold")
lines(as.data.frame(normRepr$msoa), lty = 1)
lines(as.data.frame(normRepr$ward), lty = 2)
legend("topright", c("lsoa", "msoa", "ward"), lty = c(NA,1,2), pch = c(1,NA,NA))
```
  
  Bei dieser Grafik wird mithilfe der Daten von Lsoa,Msoa und Ward die Abbildung 4 links in Aiello et al. (2020) visualisiert. Wobei man bei dieser Grafik schon einen deutlichen Unterschied zu der Grafik in Aiello sieht. Bei Aiello sind die drei Aggregationsgrade annähernd ident und nähern sich bereits bei 0.4 Threhold der X-Achse. Bei unserer Grafik verhält  sich nur Lsoa wie bei Aello und Msoa und Ward flachen erst ab 0.5 ab und schneiden erst bei 0.8 der X-Achse.

# **Aufgabe 4**
***
Abbildung 1 in Aiello et al. (2019) stellt die Verteilung der relativen Energie pro N¨ahrstoff an der Gesamtenergie dar.  
  
* Verwenden Sie die Daten fur MSOA um die Histogramme für die 6 Näahrstoffe zu erstellen. Achten Sie
auf passende Achsenbeschriftungen und stellen Sie sicher, dass die x- und y-Achsengrenzen sowie die
Intervalleinteilung bei allen Histogrammen gleich sind.
* Interpretieren Sie die Grafik.  
  

## Visualisierung

```{r}
energyTot <- yearMsoa$energy_tot
energyFatTot <- yearMsoa$energy_fat / energyTot
energyFibreTot <- yearMsoa$energy_fibre / energyTot
energySatTot <- yearMsoa$energy_saturate / energyTot
energyCarbTot <- yearMsoa$energy_carb / energyTot
energySugarTot <- yearMsoa$energy_sugar / energyTot
energyProteinTot <- yearMsoa$energy_protein / energyTot

par(mfrow=c(2,3))

h <- hist(energyCarbTot, breaks=seq(0,0.6,length=75), plot = F)
h$density <- h$counts/sum(h$counts)
plot(h, main = NULL, xlab = "Energie von Kohlenhydraten",xlim = c(0,0.6), ylim = c(0,0.6), col = "red", freq = F)

h <- hist(energyFatTot, breaks=seq(0,0.6,length=75), plot = F)
h$density <- h$counts/sum(h$counts)
plot(h, main = NULL, xlab = "Energie von Fetten",xlim = c(0,0.6), ylim = c(0,0.6), col = "purple", freq = F)

h <- hist(energySatTot, breaks=seq(0,0.6,length=75), plot = F)
h$density <- h$counts/sum(h$counts)
plot(h, main = NULL, xlab = "Energie von Saturated",xlim = c(0,0.6), ylim = c(0,0.6), col = "pink", freq = F)

h <- hist(energySugarTot, breaks=seq(0,0.6,length=75), plot = F)
h$density <- h$counts/sum(h$counts)
plot(h, main = NULL, xlab = "Energie von Zucker",xlim = c(0,0.6), ylim = c(0,0.6), col = "orange", freq = F)

h <- hist(energyProteinTot, breaks=seq(0,0.6,length=75), plot = F)
h$density <- h$counts/sum(h$counts)
plot(h, main = NULL, xlab = "Energie von Eiweiß",xlim = c(0,0.6), ylim = c(0,0.6), col = "green", freq = F)

h <- hist(energyFibreTot, breaks=seq(0,0.6,length=75), plot = F)
h$density <- h$counts/sum(h$counts)
plot(h, main = NULL, xlab = "Energie von Ballaststoffe",xlim = c(0,0.6), ylim = c(0,0.6), col = "lightgreen", freq = F)
```

Bei diesen 6 Histogrammen haben wir die Energie der 6 Nährstoffe dargestellt. Auf der Y-Achse ist die Dichte und auf der X-Achse die Energie Abgebildet. Der Nährstoff mit der meisten Energie ist das Fett welches zwischen 0.4 und 0.5 bewegt. Danach kommen Kohlenhydrate, Zucker, Satured, Eiweiß und am wenigsten Energie haben die Ballaststoffe.


# **Aufgabe 5**
***
Die Datei diabetes_estimates_osward_2016.csv enthält Gesundheitsinformationen auf Ward Level. Die Ward Level Information ist auch enthalten in statistical-gis-boundaries-london/ESRI/London_Ward_CityMerged.shp bzw.
London-wards-2014/London-wards-2014_ESRI/London_Ward_CityMerged.shp.
Schreiben Sie eine Funktion, die die Erhebungseinheiten in x mit den Erhebungseinheiten y anhand von id.x
bzw. id.y verknüpft und folgende Information zurückgibt: wie viele Einheiten sind sowohl in x als auch in y,
sind nur in x bzw. nur in y, wendet FUN auf die Variablen var.x und var.y an je nach Gruppierung, ob die
Erhebungseinheit sowohl in x als auch in y ist, nur in x bzw. nur in y ist.  
> compare_data <- function(x, y, id.x, id.y = id.x, var.x = character(0),
+ var.y = var.x, FUN = sum, ...) {
+ ...
+ }  
  
* Überprüfen Sie die Argumente und geben Sie passende Fehlermeldungen aus. Das ... Argument soll
der Funktion FUN ubergeben werden.
* Geben Sie einen Dataframe zurück, der die drei Gruppen in den Zeilen und die Anzahl sowie das Ergebnis von FUN jeweils in den Spalten hat.
* Wenden Sie die Funktion an, indem Sie x gleich den Daten in
statistical-gis-boundaries-london/ESRI/London_Ward_CityMerged.shp setzen und y gleich
den Daten in London-wards-2014/London-wards-2014_ESRI/London_Ward_CityMerged.shp setzen.
Bestimmen Sie die passenden ID Variablen und wählen Sie die Fläche jeweils als Variable.
* Wenden Sie die Funktion an, indem Sie x gleich den Daten in
diabetes_estimates_osward_2016.csv setzen und y gleich den Daten in
London-wards-2014/London-wards-2014_ESRI/London_Ward_CityMerged.shp setzen. Bestimmen Sie
die passenden ID Variablen und wählen Sie die Fläche als Variable.
* Wenden Sie weiters die Funktion an, indem Sie x gleich den Daten in
diabetes_estimates_osward_2016.csv setzen und y gleich den Daten in year_osward_grocery.csv
setzen. Bestimmen Sie die passenden ID Variablen und wählen Sie die Fläche und Bevölkerung als
Variablen.
* Interpretieren Sie die Ergebnisse. 
  
  



## Einlesen der Daten

```{r results="hide"}
diabetes <- read.table("diabetes_estimates_osward_2016.csv", header = TRUE, sep = ",")
head(diabetes)

londonWardX <- st_read("./statistical-gis-boundaries-london/statistical-gis-boundaries-london/ESRI/London_Ward_CityMerged.shp")
londonWardY <- st_read("./London-wards-2014/London-wards-2014 (1)/London-wards-2014_ESRI/London_Ward_CityMerged.shp")
```

## Funktion

```{r results="hide"}
compare_data <- function(x, y, id.x, id.y = id.x, var.x = character(0), var.y = var.x, FUN = sum, ...) {
  # Argumentüberprüfung muss noch bearbeitet werden!!!
  
  # Zwei Listen müssen übergeben werden, ansonsten nicht genügend Daten
  if(!is.list(x) | !is.list(y))
    stop("Bitte überprüfen Sie Ihre Eingabe für x und y!")
  # ID muss als String übergeben werden (zumindest x, y nicht unbedingt. Wenn y übergeben wird, muss es auch ein String sein)
  if(!is.character(id.x) | ((id.x != id.y) & !is.character(id.y)))
    stop("es muss eine korrekte ID angegeben werden!")
  # Variable muss als String übergeben werden (zumindest x, y nicht unbedingt. Wenn y übergeben wird, muss es auch ein String sein)
  if(!is.character(var.x) | ((var.x != var.y) & !is.character(var.y)))
    stop("es muss eine korrekte Variable angegeben werden!")
  
  
  #spezielle Behandlung bei merge von 2 sf Objekten (vllt st_join) muss man sich noch anschauen
  if(class(x)[1] == "sf" & class(y)[1] == "sf"){
    mergedXandY <- merge(x %>% as.data.frame(), y %>% as.data.frame(), by.x = id.x, by.y = id.y)
    mergedXandY %>% st_sf(sf_column_name = 'geometry.x')
    mergedX <- merge(x %>% as.data.frame(), y %>% as.data.frame(), by.x = id.x, by.y = id.y, all.x = TRUE)
    mergedX %>% st_sf(sf_column_name = 'geometry.x')
    mergedY <- merge(x %>% as.data.frame(), y %>% as.data.frame(), by.x = id.x, by.y = id.y, all.y = TRUE)
    mergedY %>% st_sf(sf_column_name = 'geometry.y')
    
    sumXandY <- (FUN(get(paste(var.x, ".x",sep = ""), mergedXandY), ...))
    sumX <- (FUN(get(paste(var.x,".x",sep = ""), mergedX), ...))
    sumY <- (FUN(get(paste(var.x,".y",sep = ""), mergedY),...))
  }
  else{
    mergedXandY <- merge(x, y, by.x = id.x, by.y = id.y)
    mergedX <- merge(x, y, by.x = id.x, by.y = id.y, all.x = TRUE)
    mergedY <- merge(x, y, by.x = id.x, by.y = id.y, all.y = TRUE)
    
    sumXandY <- (FUN(get(var.x, mergedXandY), ...))
    sumX <- (FUN(get(var.x, mergedX), ...))
    sumY <- (FUN(get(var.x, mergedY),...))
  }
  
  
  df <- data.frame(mergeType = c("X und Y", "nur X", "nur Y"), 
                   anzahl = c(nrow(mergedXandY),nrow(mergedX)-nrow(mergedXandY), nrow(mergedY)-nrow(mergedXandY)),
                   hektar = c(round(sumXandY,0), round(sumX-sumXandY,0), round(sumY-sumXandY,0)))
  
  # wenn separate Variablen betrachtet werden sollen
  if(var.x != var.y){
    popXandY <- (FUN(get(var.y, mergedXandY), ...))
    popX <- (FUN(get(var.y, mergedX), ...))
    popY <- (FUN(get(var.y, mergedY), ...))
    df$hektar <- df$hektar*100
    df <- cbind(df, bevölkerung = c(popXandY, popX-popXandY, popY-popXandY))
  }
 
  return(df)
}
```

## Anwendung der Funktion

```{r}
compare_data(londonWardX, londonWardY, "GSS_CODE", "GSS_CODE", "HECTARES", "HECTARES", na.rm = TRUE)
compare_data(diabetes, londonWardY, "area_id", "GSS_CODE", "HECTARES", na.rm= TRUE)
compare_data(diabetes, yearOsward, "area_id", "area_id", "area_sq_km", "population", na.rm = TRUE)
```


# **Aufgabe 6**
***
Verknüpfen Sie die Daten aus year_osward_grocery.csv mit der Information in
diabetes_estimates_osward_2016.csv.  
  
* Bestimmen Sie mithilfe Spearman Korrelation, ob es einen Zusammenhang zwischen der geschätzten
Diabetes Prävalenz und der Energie der Nährstoffe gibt.
* Visualisieren Sie in einem Streudiagramm den Zusammenhang zwischen der geschätzten Diabetes Prävalenz und der Energie der Nährstoffe.
* Interpretieren Sie das Ergebnis. Gibt es empirische Evidenz, dass sich das Kaufverhalten im Supermarkt
auf die geschätzte Diabetes Prävalenz auswirkt.  
  
## Verknuepfung der Daten

```{r results="hide"}
merged <- merge(yearOsward, diabetes, by= "area_id")
```

## Berechnung des Zusammenhangs

```{r}
corr <- cor.test(merged$estimated_diabetes_prevalence, merged$energy_tot, method = "spearman")
corr
```

## Visualisierung

```{r}
par(mfrow=c(1,1))
plot(merged$estimated_diabetes_prevalence, merged$energy_tot, main = "Streudiagramm", xlab = "geschätzte Diabetes-Prävalenz", ylab = "Energie der Nährstoffe")
```

Bei dieser Aufgabe wurden die Daten aus year_osward_grocery.csv mit der Information in
diabetes_estimates_osward_2016.csv. verknüpft und die Korrelation zwischen der geschätzten 
Diabetes Praevalenz und der Energie der Nährstoffe berechnet und mit einem Streudiagramm visualisiert. Die Korrelation mithilfe von Spearman ist 0.58 alos gibt es einen starken positiven Zusammenhang der beiden Vriablen. Dieses Ergebnis bestätigt das Streudiagramm welches eine positive Steigung hat. 
